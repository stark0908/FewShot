{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "73ca085a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch sees 8 GPUs\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(\"PyTorch sees\", torch.cuda.device_count(), \"GPUs\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5ee91f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU cores available: 80\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(\"CPU cores available:\", os.cpu_count())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c6624c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torch\n",
    "import os\n",
    "import random\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ad8488f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets.utils import download_and_extract_archive\n",
    "from torchvision.datasets.folder import ImageFolder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5da86ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transform=transforms.Compose([\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485,0.456,0.406],\n",
    "                         std=[0.229,0.224,0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "223056ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(\"/home/23dcs505/data/2750\"):\n",
    "    print(\"No dataset found\")\n",
    "fulldata=ImageFolder(root='/home/23dcs505/data/2750', transform=data_transform)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "07a019bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import random_split\n",
    "\n",
    "train_len=int((0.8)*len(fulldata))\n",
    "test_len=len(fulldata)-(train_len)\n",
    "\n",
    "train_data_set,test_data_set= random_split(fulldata,[train_len, test_len])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d1075bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_list=[0,1,2,3,4,5,6,7,8,9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7d2c4065",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_class_len=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9eb9e835",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_list=random.sample(all_list,train_class_len)\n",
    "test_list=list(range(0,10))\n",
    "strict_test_list=list(set(all_list) - set(train_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dec17bec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5, 9, 0]\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "[1, 2, 3, 4, 6, 7, 8]\n"
     ]
    }
   ],
   "source": [
    "print(train_list)\n",
    "print(test_list)\n",
    "print(strict_test_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "43fe318f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ways=3\n",
    "shots=5\n",
    "queries=5\n",
    "strict_ways=len(strict_test_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2ea19459",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e1639b2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16085"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_set.indices[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "be71adb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_sorting(dataset, class_list):\n",
    "    targets = dataset.dataset.targets\n",
    "\n",
    "    indices= [i for i in dataset.indices if targets[i] in class_list]\n",
    "    return Subset(dataset.dataset, indices)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1c9800fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data=class_sorting(train_data_set,train_list)\n",
    "test_data=class_sorting(test_data_set,test_list)\n",
    "strict_test_data=class_sorting(test_data,strict_test_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ced87a0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[-1.6213, -1.6213, -1.6213,  ..., -1.6384, -1.6384, -1.6384],\n",
       "          [-1.6213, -1.6213, -1.6213,  ..., -1.6384, -1.6384, -1.6384],\n",
       "          [-1.6213, -1.6213, -1.6213,  ..., -1.6384, -1.6384, -1.6384],\n",
       "          ...,\n",
       "          [-1.6213, -1.6213, -1.6213,  ..., -1.6042, -1.6042, -1.6042],\n",
       "          [-1.6213, -1.6213, -1.6213,  ..., -1.6042, -1.6042, -1.6042],\n",
       "          [-1.6213, -1.6213, -1.6213,  ..., -1.6042, -1.6042, -1.6042]],\n",
       " \n",
       "         [[-1.1604, -1.1604, -1.1604,  ..., -1.1604, -1.1604, -1.1604],\n",
       "          [-1.1604, -1.1604, -1.1604,  ..., -1.1604, -1.1604, -1.1604],\n",
       "          [-1.1604, -1.1604, -1.1604,  ..., -1.1604, -1.1604, -1.1604],\n",
       "          ...,\n",
       "          [-1.1429, -1.1429, -1.1429,  ..., -1.1604, -1.1604, -1.1604],\n",
       "          [-1.1429, -1.1429, -1.1429,  ..., -1.1604, -1.1604, -1.1604],\n",
       "          [-1.1429, -1.1429, -1.1429,  ..., -1.1604, -1.1604, -1.1604]],\n",
       " \n",
       "         [[-0.4624, -0.4624, -0.4624,  ..., -0.5147, -0.5147, -0.5147],\n",
       "          [-0.4624, -0.4624, -0.4624,  ..., -0.5147, -0.5147, -0.5147],\n",
       "          [-0.4624, -0.4624, -0.4624,  ..., -0.5147, -0.5147, -0.5147],\n",
       "          ...,\n",
       "          [-0.4973, -0.4973, -0.4973,  ..., -0.4624, -0.4624, -0.4624],\n",
       "          [-0.4973, -0.4973, -0.4973,  ..., -0.4624, -0.4624, -0.4624],\n",
       "          [-0.4973, -0.4973, -0.4973,  ..., -0.4624, -0.4624, -0.4624]]]),\n",
       " 9)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f7951d44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset ImageFolder\n",
       "    Number of datapoints: 27000\n",
       "    Root location: /home/23dcs505/data/2750\n",
       "    StandardTransform\n",
       "Transform: Compose(\n",
       "               Resize(size=(224, 224), interpolation=bilinear, max_size=None, antialias=None)\n",
       "               ToTensor()\n",
       "               Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
       "           )"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "train_data.dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9314ea94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25019"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.indices[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "35037a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class create_dataset(Dataset):\n",
    "    def __init__(self,data,way,shot,query,episode):\n",
    "        super().__init__()\n",
    "        self.data=data\n",
    "        self.way=way\n",
    "        self.shot=shot\n",
    "        self.query=query\n",
    "        self.episode=episode\n",
    "\n",
    "        self.class_to_indices=self._build_class_index()\n",
    "        self.classes=list(self.class_to_indices.keys())\n",
    "        \n",
    "\n",
    "    def _build_class_index(self):\n",
    "        class_index={}\n",
    "\n",
    "        targets=self.data.dataset.targets\n",
    "\n",
    "        labels = [self.data.dataset.targets[i] for i in self.data.indices]\n",
    "        \n",
    "\n",
    "\n",
    "        for indexofsubset, indexoforiginal in enumerate(self.data.indices):\n",
    "            label=targets[indexoforiginal]\n",
    "            if label not in class_index:\n",
    "                class_index[label]=[]\n",
    "            class_index[label].append(indexofsubset)\n",
    "\n",
    "        return class_index\n",
    "        \n",
    "    def __len__(self):\n",
    "            return self.episode\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        #print('hello')\n",
    "\n",
    "        #print(f\"Total available classes: {len(self.classes)}, requested way: {self.way}\")\n",
    "\n",
    "\n",
    "        selected_class=random.sample(self.classes,self.way)\n",
    "\n",
    "        support_images, support_labels=[],[]\n",
    "        query_images, query_labels=[],[]\n",
    "\n",
    "\n",
    "        label_map={class_name: i for i, class_name in enumerate(selected_class)}\n",
    "\n",
    "        for class_name in selected_class:\n",
    "            all_indices_for_class=self.class_to_indices[class_name]\n",
    "\n",
    "            selected_index=random.sample(all_indices_for_class,self.shot+self.query)\n",
    "\n",
    "            support_index=selected_index[:self.shot]\n",
    "            query_index=selected_index[self.shot:]\n",
    "\n",
    "            for i in support_index:\n",
    "                image,_=self.data[i]\n",
    "                support_images.append(image)\n",
    "                support_labels.append(torch.tensor(label_map[class_name]))\n",
    "                \n",
    "            for i in query_index:\n",
    "                image,_=self.data[i]\n",
    "                query_images.append(image)\n",
    "                query_labels.append(torch.tensor(label_map[class_name]))\n",
    "            \n",
    "        return(\n",
    "            torch.stack(support_images),\n",
    "            torch.stack(support_labels),\n",
    "            torch.stack(query_images),\n",
    "            torch.stack(query_labels)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c4451cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_prototypes(support_embeddings,support_labels,way):\n",
    "    embedding_dimensions=support_embeddings.size(-1)\n",
    "    prototypes=torch.zeros(way,embedding_dimensions).to(support_embeddings.device)\n",
    "\n",
    "    for c in range(way):\n",
    "        class_mask=(support_labels==c)\n",
    "        class_embeddings=support_embeddings[class_mask]\n",
    "        prototypes[c]=class_embeddings.mean(dim=0)\n",
    "    return prototypes\n",
    "\n",
    "def classify_queries(prototypes,query_embeddings):\n",
    "    n_query=query_embeddings.size(0)\n",
    "    way=prototypes.size(0)\n",
    "\n",
    "    query_exp=query_embeddings.unsqueeze(1).expand(n_query,way,-1)\n",
    "    prototypes_exp=prototypes.unsqueeze(0).expand(n_query,way,-1)\n",
    "\n",
    "    distances=torch.sum((query_exp-prototypes_exp)**2,dim=2)\n",
    "\n",
    "    logits=-distances\n",
    "    return logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "775c60ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "few_dataset=create_dataset(\n",
    "    data=train_data,\n",
    "    way=ways,\n",
    "    shot=shots,\n",
    "    query=queries,\n",
    "    episode=200\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "04e9bf6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "few_dataloader=DataLoader(\n",
    "    few_dataset,\n",
    "    #batch_size=1,\n",
    "    shuffle=True,\n",
    "    num_workers=8, \n",
    "    pin_memory=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e85f9116",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "vgg=models.vgg16(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ffd51202",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGGEmbedding(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "\n",
    "        # ##Code from the paper\n",
    "        # features_list = list(vgg.features.children())\n",
    "        # # Insert DropBlock after MaxPool at index 16\n",
    "        # features_list.insert(17, DropBlock2D(block_size=block_size, drop_prob=drop_prob))\n",
    "        # # Insert DropBlock after MaxPool at index 23 (now 24 due to previous insertion)\n",
    "        # features_list.insert(24, DropBlock2D(block_size=block_size, drop_prob=drop_prob))\n",
    "        # ##END\n",
    "\n",
    "\n",
    "        self.features=vgg.features\n",
    "        self.avgpool=vgg.avgpool\n",
    "\n",
    "        self.classifier=nn.Sequential(*list(vgg.classifier.children())[:-1])\n",
    "\n",
    "    def forward(self,x):\n",
    "        x=self.features(x)\n",
    "        x=self.avgpool(x)\n",
    "        x=torch.flatten(x,1)\n",
    "        x=self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4604d5dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7ee9daab",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=VGGEmbedding()\n",
    "\n",
    "\n",
    "# 1. Freeze all layers first\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# 2. Unfreeze the last convolutional block (block 5)\n",
    "# The VGG16 features list has 31 layers. Block 5 starts at index 24.\n",
    "for param in model.features[24:].parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "# 3. Unfreeze the classifier and replace the last layer\n",
    "model.classifier[3] = nn.Linear(model.classifier[3].in_features, 256)\n",
    "\n",
    "for param in model.classifier.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "device=torch.device(\"cuda:2\" if torch.cuda.is_available() else \"cpu\")\n",
    "model=model.to(device)\n",
    "\n",
    "trainable_params = filter(lambda p: p.requires_grad, model.parameters())\n",
    "optimizer = optim.Adam(trainable_params, lr=1e-4)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "epochs=20\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "697e03ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on class : [5, 9, 0]\n"
     ]
    }
   ],
   "source": [
    "print(\"training on class :\",train_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2a9a29ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import gc\n",
    "\n",
    "gc.collect()  # Python garbage collection\n",
    "torch.cuda.empty_cache()  # Clear cache for current device\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "de3857d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 ------------- Loss= 0.22790205305151176 Acccuracy= 93.76666666666667\n",
      "Epoch: 2 ------------- Loss= 0.07753565326440366 Acccuracy= 97.36666666666667\n",
      "Epoch: 3 ------------- Loss= 0.09333320378897952 Acccuracy= 97.16666666666667\n",
      "Epoch: 4 ------------- Loss= 0.10415965393103484 Acccuracy= 97.66666666666667\n",
      "Epoch: 5 ------------- Loss= 0.04421461799503391 Acccuracy= 98.73333333333333\n",
      "Epoch: 6 ------------- Loss= 0.04410038689420844 Acccuracy= 98.9\n",
      "Epoch: 7 ------------- Loss= 0.02829293905401755 Acccuracy= 99.33333333333333\n",
      "Epoch: 8 ------------- Loss= 0.015706479383538863 Acccuracy= 99.66666666666667\n",
      "Epoch: 9 ------------- Loss= 0.054929374042822235 Acccuracy= 98.86666666666667\n",
      "Epoch: 10 ------------- Loss= 0.030878585080907895 Acccuracy= 99.03333333333333\n",
      "Epoch: 11 ------------- Loss= 0.11672872548387801 Acccuracy= 97.8\n",
      "Epoch: 12 ------------- Loss= 0.04096086663189631 Acccuracy= 98.96666666666667\n",
      "Epoch: 13 ------------- Loss= 0.013386597071989853 Acccuracy= 99.63333333333333\n",
      "Epoch: 14 ------------- Loss= 0.035206290309176824 Acccuracy= 99.23333333333333\n",
      "Epoch: 15 ------------- Loss= 0.02466301519925423 Acccuracy= 99.13333333333333\n",
      "Epoch: 16 ------------- Loss= 0.07922126903445564 Acccuracy= 98.83333333333333\n",
      "Epoch: 17 ------------- Loss= 0.043969319214550676 Acccuracy= 98.96666666666667\n",
      "Epoch: 18 ------------- Loss= 0.006249967291490712 Acccuracy= 99.8\n",
      "Epoch: 19 ------------- Loss= 0.01853240756949483 Acccuracy= 99.73333333333333\n",
      "Epoch: 20 ------------- Loss= 0.028705596570492452 Acccuracy= 99.3\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_loss, total_correct, total_queries= 0,0,0\n",
    "\n",
    "    for episode in few_dataloader:\n",
    "        support_images, support_labels, query_images, query_labels=episode\n",
    "        support_images=(support_images.squeeze(0)).to(device, non_blocking=True)\n",
    "        query_images=(query_images.squeeze(0)).to(device, non_blocking=True)\n",
    "        support_labels=(support_labels.view(-1)).to(device, non_blocking=True)\n",
    "        query_labels=(query_labels.view(-1)).to(device, non_blocking=True)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        support_embeddings=model(support_images)\n",
    "        query_embeddings=model(query_images)\n",
    "\n",
    "        n_way=torch.unique(support_labels).size(0)\n",
    "        prototypes=compute_prototypes(support_embeddings,support_labels,n_way)\n",
    "        logits=classify_queries(prototypes,query_embeddings)\n",
    "        loss=loss_fn(logits,query_labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss+=loss.item()\n",
    "        preds=torch.argmax(logits,dim=1)\n",
    "        total_correct+=(preds==query_labels).sum().item()\n",
    "        total_queries+=query_labels.size(0)\n",
    "    \n",
    "    avg_loss=total_loss/len(few_dataloader)\n",
    "    accuracy=(total_correct/total_queries)*100\n",
    "    print(\"Epoch:\",epoch+1,\"-------------\",\"Loss=\",avg_loss,\"Acccuracy=\",accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f78e1809",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset=create_dataset(\n",
    "    data=test_data,\n",
    "    way=ways,\n",
    "    shot=shots,\n",
    "    query=queries,\n",
    "    episode=200\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "532fa90c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataloader=DataLoader(\n",
    "    test_dataset,\n",
    "    shuffle=True,\n",
    "    num_workers=8, \n",
    "    pin_memory=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9236e5eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing on class : [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n"
     ]
    }
   ],
   "source": [
    "print(\"testing on class :\",test_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "27b5c9bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss= 0.028705596570492452 Acccuracy on 10 Class = 66.43333333333334\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "total_correct, total_queries= 0,0\n",
    "with torch.no_grad():\n",
    "    for episode in test_dataloader:\n",
    "        support_images, support_labels, query_images, query_labels=episode\n",
    "        support_images=(support_images.squeeze(0)).to(device, non_blocking=True)\n",
    "        query_images=(query_images.squeeze(0)).to(device, non_blocking=True)\n",
    "        support_labels=(support_labels.view(-1)).to(device, non_blocking=True)\n",
    "        query_labels=(query_labels.view(-1)).to(device, non_blocking=True)\n",
    "\n",
    "        support_embeddings=model(support_images)\n",
    "        query_embeddings=model(query_images)\n",
    "\n",
    "        n_way=torch.unique(support_labels).size(0)\n",
    "        prototypes=compute_prototypes(support_embeddings,support_labels,n_way)\n",
    "        logits=classify_queries(prototypes,query_embeddings)\n",
    "        \n",
    "        preds=torch.argmax(logits,dim=1)\n",
    "        total_correct+=(preds==query_labels).sum().item()\n",
    "        total_queries+=query_labels.size(0)\n",
    "    \n",
    "    #avg_loss=total_loss/len(few_dataloader)\n",
    "    accuracy=(total_correct/total_queries)*100\n",
    "    print(\"Loss=\",avg_loss,\"Acccuracy on\", len(test_list),\"Class =\",accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fd745aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "strict_test_dataset=create_dataset(\n",
    "    data=strict_test_data,\n",
    "    way=strict_ways,\n",
    "    shot=shots,\n",
    "    query=queries,\n",
    "    episode=200\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "96358b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "strict_test_dataloader=DataLoader(\n",
    "    strict_test_dataset,\n",
    "    #batch_size=1,\n",
    "    shuffle=True,\n",
    "    num_workers=8, \n",
    "    pin_memory=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a2277cff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing on class : [1, 2, 3, 4, 6, 7, 8]\n"
     ]
    }
   ],
   "source": [
    "print(\"testing on class :\",strict_test_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f10aba1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss= 0.028705596570492452 Acccuracy on 7 Class = 29.271428571428572\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "total_correct, total_queries= 0,0\n",
    "with torch.no_grad():\n",
    "    for episode in strict_test_dataloader:\n",
    "        support_images, support_labels, query_images, query_labels=episode\n",
    "        support_images=(support_images.squeeze(0)).to(device, non_blocking=True)\n",
    "        query_images=(query_images.squeeze(0)).to(device, non_blocking=True)\n",
    "        support_labels=(support_labels.view(-1)).to(device, non_blocking=True)\n",
    "        query_labels=(query_labels.view(-1)).to(device, non_blocking=True)\n",
    "\n",
    "        support_embeddings=model(support_images)\n",
    "        query_embeddings=model(query_images)\n",
    "\n",
    "        n_way=torch.unique(support_labels).size(0)\n",
    "        prototypes=compute_prototypes(support_embeddings,support_labels,n_way)\n",
    "        logits=classify_queries(prototypes,query_embeddings)\n",
    "        \n",
    "        preds=torch.argmax(logits,dim=1)\n",
    "        total_correct+=(preds==query_labels).sum().item()\n",
    "        total_queries+=query_labels.size(0)\n",
    "    \n",
    "    #avg_loss=total_loss/len(few_dataloader)\n",
    "    accuracy=(total_correct/total_queries)*100\n",
    "    print(\"Loss=\",avg_loss,\"Acccuracy on\", len(strict_test_list),\"Class =\",accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b19bd3f",
   "metadata": {},
   "source": [
    "**Stable Protypical Network**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0e16ec90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import gc\n",
    "\n",
    "# Delete all unused objects\n",
    "gc.collect()\n",
    "\n",
    "# Empty PyTorch CUDA cache\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ea490bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dropblock import DropBlock2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5087d587",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.cuda.amp import autocast, GradScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f421c392",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "525c3ca8d5544b418601c72da1ce155d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/20:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 ------------- Loss= 2.538295323550701 Acccuracy= 84.26666666666667\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6cf0114ebf0c485f856bacdbec8911bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2/20:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 ------------- Loss= 0.8072832859493793 Acccuracy= 94.6\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4a6d4b9e2d94d91b3c797140c38e15b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3/20:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3 ------------- Loss= 0.5867871993314475 Acccuracy= 96.83333333333334\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ddcdbfb36a14f1385895622ea63d381",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4/20:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4 ------------- Loss= 0.3597478022542782 Acccuracy= 98.13333333333333\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1439421738764f6c904b9fedeee82f3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5/20:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 ------------- Loss= 0.3092515488702338 Acccuracy= 98.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cec031df5a1246ab97d0c46f145dea2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 6/20:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6 ------------- Loss= 0.23891570526640862 Acccuracy= 98.46666666666667\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27411a53cf44422c93680ee6d6243158",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 7/20:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7 ------------- Loss= 0.21240038631862262 Acccuracy= 98.73333333333333\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7972955e0229452aa1bc6868bc6bbd75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 8/20:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8 ------------- Loss= 0.14517389148371876 Acccuracy= 99.13333333333333\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae8b2bbc433649f69aac80842fa5d99f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 9/20:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9 ------------- Loss= 0.19114242820593064 Acccuracy= 99.23333333333333\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ea52781ee0449a49fffff797d3f0ce1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 10/20:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 ------------- Loss= 0.10323280909447931 Acccuracy= 99.5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c26780424724a19a0938e0cffaa1322",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 11/20:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11 ------------- Loss= 0.09992190586743163 Acccuracy= 99.23333333333333\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a15de863afd494db19bc3ac888b39ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 12/20:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12 ------------- Loss= 0.1424202796656391 Acccuracy= 99.26666666666667\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e20288125a214d849dff6cdaae09d239",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 13/20:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 13 ------------- Loss= 0.10664852139554569 Acccuracy= 99.1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55a61c3a0b74456c90604309e13edfaf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 14/20:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14 ------------- Loss= 0.068071213621879 Acccuracy= 99.76666666666667\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ef3a08093ee49719782f1e87e351cdb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 15/20:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15 ------------- Loss= 0.06351958364786697 Acccuracy= 99.7\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bb5f2a956774c5a93b670078facf113",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 16/20:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 16 ------------- Loss= 0.05090420080083277 Acccuracy= 99.76666666666667\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db406bb901424ac2aeb5418559b69523",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 17/20:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 17 ------------- Loss= 0.044024755224787666 Acccuracy= 99.83333333333333\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9dccb27961a541e6962e29b51f91be6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 18/20:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 18 ------------- Loss= 0.060671954464414736 Acccuracy= 99.7\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d62716a814d640d4857a78b3a2c5660d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 19/20:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 19 ------------- Loss= 0.04098398191972592 Acccuracy= 99.76666666666667\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85a04856c8aa4a2a9a3a9e55bfaf9cf7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 20/20:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 20 ------------- Loss= 0.03762057566924341 Acccuracy= 99.66666666666667\n",
      "Testing........... Started.......................\n",
      "Loss= 0.03762057566924341 Acccuracy on 10 Class = 71.43333333333334\n",
      "Mean Predictive Entropy = 0.6568796038627625\n"
     ]
    }
   ],
   "source": [
    "import torchvision.models as models\n",
    "vgg=models.vgg16(pretrained=True)\n",
    "class VGGEmbedding(nn.Module):\n",
    "    def __init__(self,drop_prob=0.3, block_size=5):\n",
    "        super().__init__()\n",
    "\n",
    "\n",
    "        ##Code from the paper\n",
    "        features_list = list(vgg.features.children())\n",
    "        # Insert DropBlock after MaxPool at index 16\n",
    "        features_list.insert(17, DropBlock2D(block_size=block_size, drop_prob=drop_prob))\n",
    "        # Insert DropBlock after MaxPool at index 23 (now 24 due to previous insertion)\n",
    "        features_list.insert(24, DropBlock2D(block_size=block_size, drop_prob=drop_prob))\n",
    "        ##END\n",
    "\n",
    "\n",
    "        self.features=nn.Sequential(*features_list)\n",
    "        self.avgpool=vgg.avgpool\n",
    "\n",
    "        self.classifier=nn.Sequential(*list(vgg.classifier.children())[:-1])\n",
    "\n",
    "    def forward(self,x):\n",
    "        x=self.features(x)\n",
    "        x=self.avgpool(x)\n",
    "        x=torch.flatten(x,1)\n",
    "        x=self.classifier(x)\n",
    "        return x\n",
    "\n",
    "model=VGGEmbedding()\n",
    "\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "for layer in model.features[26:]: # Layers from the original Block 5 onwards\n",
    "    # Check if the layer has parameters (e.g., Conv2d does, MaxPool2d doesn't)\n",
    "    if hasattr(layer, 'parameters'):\n",
    "        for param in layer.parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "# 3. Unfreeze the classifier and ensure the final layer is replaced\n",
    "model.classifier[3] = nn.Linear(model.classifier[3].in_features, 256)\n",
    "for param in model.classifier.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "# 4. Set up optimizer with ONLY the trainable parameters\n",
    "device = torch.device(\"cuda:2\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "trainable_params = filter(lambda p: p.requires_grad, model.parameters())\n",
    "optimizer = optim.Adam(trainable_params, lr=1e-5) # Use a smaller LR for fine-tuning\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "epochs=20\n",
    "\n",
    "#From code for SPN\n",
    "n_times=5\n",
    "alpha=1.0\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_loss, total_correct, total_queries= 0,0,0\n",
    "\n",
    "    from tqdm.notebook import tqdm\n",
    "    progress_bar=tqdm(few_dataloader, desc=f\"Epoch {epoch+1}/{epochs}\",leave=False)\n",
    "\n",
    "\n",
    "    for episode in progress_bar:\n",
    "        support_images, support_labels, query_images, query_labels=episode\n",
    "        support_images=(support_images.squeeze(0)).to(device, non_blocking=True)\n",
    "        query_images=(query_images.squeeze(0)).to(device, non_blocking=True)\n",
    "        support_labels=(support_labels.view(-1)).to(device, non_blocking=True)\n",
    "        query_labels=(query_labels.view(-1)).to(device, non_blocking=True)\n",
    "\n",
    "\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        #For montecarlopass\n",
    "        \n",
    "        all_ce_losses = []\n",
    "        all_query_logits = []\n",
    "\n",
    "        for _ in range(n_times):\n",
    "            support_embeddings=model(support_images)\n",
    "            query_embeddings=model(query_images)\n",
    "\n",
    "            n_way=torch.unique(support_labels).size(0)\n",
    "            prototypes=compute_prototypes(support_embeddings,support_labels,n_way)\n",
    "            logits=classify_queries(prototypes,query_embeddings)\n",
    "\n",
    "            ce_loss=loss_fn(logits,query_labels)\n",
    "            all_ce_losses.append(ce_loss)\n",
    "            all_query_logits.append(logits)\n",
    "            \n",
    "        total_ce_loss= torch.stack(all_ce_losses).sum()\n",
    "\n",
    "        stacked_logits=torch.stack(all_query_logits)\n",
    "        stacked_probs=torch.softmax(stacked_logits,dim=-1)\n",
    "\n",
    "        true_class_probs = stacked_probs[\n",
    "            torch.arange(n_times)[:, None],\n",
    "            torch.arange(len(query_labels)),\n",
    "            query_labels\n",
    "        ]\n",
    "            \n",
    "        variance_loss=torch.std(true_class_probs,dim=0).mean()\n",
    "        total_combined_loss=total_ce_loss+alpha*variance_loss\n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "        total_combined_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        mean_logits=stacked_logits.mean(dim=0)\n",
    "        total_loss+=total_combined_loss.item()\n",
    "        preds=torch.argmax(logits,dim=1)\n",
    "        total_correct+=(preds==query_labels).sum().item()\n",
    "        total_queries+=query_labels.size(0)\n",
    "\n",
    "        avg_acc_till=(total_correct/total_queries)*100\n",
    "        progress_bar.set_postfix(Loss=f\"{total_combined_loss.item():4f}\",Acc=f\"{avg_acc_till}&\")\n",
    "    \n",
    "    avg_loss=total_loss/len(few_dataloader)\n",
    "    accuracy=(total_correct/total_queries)*100\n",
    "    print(\"Epoch:\",epoch+1,\"-------------\",\"Loss=\",avg_loss,\"Acccuracy=\",accuracy)\n",
    "\n",
    "print(\"Testing........... Started.......................\")\n",
    "\n",
    "model.eval()\n",
    "total_correct, total_queries= 0,0\n",
    "with torch.no_grad():\n",
    "    for episode in test_dataloader:\n",
    "        support_images, support_labels, query_images, query_labels=episode\n",
    "        support_images=(support_images.squeeze(0)).to(device, non_blocking=True)\n",
    "        query_images=(query_images.squeeze(0)).to(device, non_blocking=True)\n",
    "        support_labels=(support_labels.view(-1)).to(device, non_blocking=True)\n",
    "        query_labels=(query_labels.view(-1)).to(device, non_blocking=True)\n",
    "\n",
    "        stacked_logits=[]\n",
    "\n",
    "\n",
    "\n",
    "        model.train()\n",
    "        for _ in range(n_times):\n",
    "\n",
    "            support_embeddings=model(support_images)\n",
    "            query_embeddings=model(query_images)\n",
    "\n",
    "            n_way=torch.unique(support_labels).size(0)\n",
    "            prototypes=compute_prototypes(support_embeddings,support_labels,n_way)\n",
    "            logits=classify_queries(prototypes,query_embeddings)\n",
    "\n",
    "            stacked_logits.append(logits)\n",
    "        \n",
    "        model.eval()\n",
    "        mean_logits=torch.stack(stacked_logits).mean(dim=0)\n",
    "        preds=torch.argmax(mean_logits,dim=1)\n",
    "        total_correct+=(preds==query_labels).sum().item()\n",
    "        total_queries+=query_labels.size(0)\n",
    "\n",
    "        torch.cuda.empty_cache()\n",
    "    \n",
    "    #avg_loss=total_loss/len(few_dataloader)\n",
    "    accuracy=(total_correct/total_queries)*100\n",
    "    print(\"Loss=\",avg_loss,\"Acccuracy on\", len(test_list),\"Class =\",accuracy)\n",
    "\n",
    "\n",
    "    entropy = -(torch.softmax(mean_logits, dim=1) * torch.log_softmax(mean_logits, dim=1)).sum(dim=1).mean()\n",
    "    print(\"Mean Predictive Entropy =\", entropy.item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "025823f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss= 0.03762057566924341 Acccuracy on 7 Class = 33.68571428571428\n",
      "Mean Predictive Entropy = 1.2036287784576416\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "total_correct, total_queries= 0,0\n",
    "with torch.no_grad():\n",
    "    for episode in strict_test_dataloader:\n",
    "        support_images, support_labels, query_images, query_labels=episode\n",
    "        support_images=(support_images.squeeze(0)).to(device, non_blocking=True)\n",
    "        query_images=(query_images.squeeze(0)).to(device, non_blocking=True)\n",
    "        support_labels=(support_labels.view(-1)).to(device, non_blocking=True)\n",
    "        query_labels=(query_labels.view(-1)).to(device, non_blocking=True)\n",
    "\n",
    "        stacked_logits=[]\n",
    "\n",
    "\n",
    "\n",
    "        model.train()\n",
    "        for _ in range(n_times):\n",
    "\n",
    "            support_embeddings=model(support_images)\n",
    "            query_embeddings=model(query_images)\n",
    "\n",
    "            n_way=torch.unique(support_labels).size(0)\n",
    "            prototypes=compute_prototypes(support_embeddings,support_labels,n_way)\n",
    "            logits=classify_queries(prototypes,query_embeddings)\n",
    "\n",
    "            stacked_logits.append(logits)\n",
    "        \n",
    "        model.eval()\n",
    "        mean_logits=torch.stack(stacked_logits).mean(dim=0)\n",
    "        preds=torch.argmax(mean_logits,dim=1)\n",
    "        total_correct+=(preds==query_labels).sum().item()\n",
    "        total_queries+=query_labels.size(0)\n",
    "\n",
    "        torch.cuda.empty_cache()\n",
    "    \n",
    "    #avg_loss=total_loss/len(few_dataloader)\n",
    "    accuracy=(total_correct/total_queries)*100\n",
    "    print(\"Loss=\",avg_loss,\"Acccuracy on\", len(strict_test_list),\"Class =\",accuracy)\n",
    "\n",
    "\n",
    "    entropy = -(torch.softmax(mean_logits, dim=1) * torch.log_softmax(mean_logits, dim=1)).sum(dim=1).mean()\n",
    "    print(\"Mean Predictive Entropy =\", entropy.item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e3f1d43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc7d380",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c20908d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c65b92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a3a9fc3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51b1fce6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02dcb43a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae261156",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9af431e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4455ffaa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ca37b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65100f67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "615226d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc317b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d0e3a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
